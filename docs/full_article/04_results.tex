% =============================================================================
% CHAPTER 4: RESULTS
% =============================================================================
\chapter{Results}
\label{chap:results}

This chapter presents the experimental results of the proposed growth curve regression model for vegetation forecasting. The evaluation includes quantitative error metrics, temporal and spatial error analysis, prediction visualizations, comparison with benchmark models, and preliminary interpretability analysis.

\section{Error Metrics}

The model was evaluated on the validation set using Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) as primary metrics. Errors are computed on reflectance deltas after masking cloud-contaminated pixels.

\subsection{Per-Band Performance}

Table~\ref{tab:error_metrics} presents the error metrics for each spectral band.

\begin{table}[H]
    \centering
    \caption{Per-band error metrics on validation set}
    \label{tab:error_metrics}
    \begin{tabular}{lcc}
        \toprule
        \textbf{Band} & \textbf{MAE} & \textbf{RMSE} \\
        \midrule
        B02 (Blue) & 0.029 & 0.057 \\
        B03 (Green) & 0.032 & 0.058 \\
        B04 (Red) & 0.041 & 0.066 \\
        B8A (NIR) & 0.053 & 0.077 \\
        \midrule
        \textbf{Overall} & \textbf{0.039} & \textbf{0.064} \\
        \bottomrule
    \end{tabular}
\end{table}

Key observations:
\begin{itemize}
    \item The NIR band (B8A) shows the highest prediction error, likely due to its higher sensitivity to vegetation changes and larger dynamic range.
    \item The Blue band (B02) achieves the lowest error, consistent with its typically lower variability in vegetation-dominated scenes.
    \item Overall errors are in a reasonable range considering that predictions span a 100-day forecast horizon with delta values typically in $[-0.2, 0.2]$.
\end{itemize}

\subsection{Benchmark Performance (Vegetation Score)}

To rigorously assess the model's utility for vegetation forecasting, we computed the \textbf{Vegetation Score} defined by the GreenEarthNet benchmark ($2 - \frac{1}{\text{mean}(1/(2-\text{NSE}))}$) and compared it against a \textbf{Persistence Baseline} (assuming no change over the forecast horizon).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../../images/results/error_analysis/vegetation_score_comparison.png}
    \caption{Vegetation Score comparison between the proposed Growth Curve Model and a Persistence Baseline across different land cover types. Higher scores indicate better performance (1.0 is perfect prediction).}
    \label{fig:veg_score}
\end{figure}

As shown in Figure~\ref{fig:veg_score}, the model consistently outperforms the persistence baseline across vegetation-dominated classes (Tree cover, Shrubland, Grassland), indicating it successfully captures vegetation dynamics beyond simple static assumptions.

\section{Temporal Error Analysis}

Understanding how prediction error evolves across the forecast horizon is critical for assessing model reliability at different lead times.

\subsection{Error Evolution Over Forecast Horizon}

Figure~\ref{fig:temporal_error} shows the stacked Mean Absolute Error across the 20 forecast timesteps, disaggregated by spectral band.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../../images/results/error_analysis/temporal_error.png}
    \caption{Prediction error evolution over the 100-day forecast horizon (20 steps). The plot shows the Root Mean Square Error (RMSE) and Nash-Sutcliffe Efficiency (NSE) for kNDVI.}
    \label{fig:temporal_error}
\end{figure}

The temporal error pattern reveals:
\begin{itemize}
    \item \textbf{Error Growth}: RMSE increases and NSE decreases as the forecast horizon extends, which is expected for long-term prediction.
    \item \textbf{Stability}: The degradation is gradual, suggesting the model maintains a coherent trajectory rather than diverging rapidly. The NSE remains positive for a significant portion of the horizon, indicating skill relative to the mean.
\end{itemize}

\section{Spatial Error Analysis}

Spatial patterns in prediction error can reveal systematic difficulties with certain land cover types or image regions.

\subsection{Error Heatmap}

Figure~\ref{fig:spatial_error} shows the average absolute error across the $128 \times 128$ pixel grid, averaged over multiple validation samples and all timesteps.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{../../images/results/spatial_error_heatmap.png}
    \caption{Spatial distribution of mean absolute error, averaged across samples and forecast timesteps.}
    \label{fig:spatial_error}
\end{figure}

Observations:
\begin{itemize}
    \item Error patterns show spatial structure rather than uniform noise, suggesting systematic prediction challenges in certain regions.
    \item Edges and boundaries between land cover types may contribute to higher local errors.
    \item Cloud boundary effects and mixed pixel issues likely contribute to spatial error patterns.
\end{itemize}

\subsection{Land Cover Class Performance}

% Placeholder: Analysis by land cover class would go here when computed
Understanding prediction quality across different land cover types is important for agricultural applications. Future analysis will disaggregate error metrics by ESA WorldCover class to identify whether certain vegetation types are more challenging to forecast.

\section{Prediction Visualization}

Qualitative assessment of predictions provides insights beyond aggregate metrics.

\subsection{Ground Truth vs. Prediction Comparison}

Figures~\ref{fig:prediction_sample1} and \ref{fig:prediction_sample2} show comparisons between ground truth and predicted reflectance deltas for two validation samples across multiple forecast timesteps.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../../images/results/prediction_comparison_1.png}
    \caption{Sample 1: Ground truth (top row) vs. predicted (bottom row) reflectance deltas across forecast timesteps. RGB visualization maps delta values to color channels.}
    \label{fig:prediction_sample1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../../images/results/prediction_comparison_2.png}
    \caption{Sample 2: Ground truth (top row) vs. predicted (bottom row) reflectance deltas across forecast timesteps.}
    \label{fig:prediction_sample2}
\end{figure}

The visualizations demonstrate:
\begin{itemize}
    \item The model captures the overall spatial structure of vegetation changes.
    \item Temporal progression of predicted deltas follows physically plausible patterns.
    \item Some smoothing of fine-scale features is apparent, likely due to the spatial smoothing layer and limited model capacity.
\end{itemize}

\section{Model Comparison}

Table~\ref{tab:model_comparison} compares the proposed approach with published results on the GreenEarthNet benchmark.

\begin{table}[H]
    \centering
    \caption{Model comparison on GreenEarthNet benchmark}
    \label{tab:model_comparison}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Model} & \textbf{Parameters} & \textbf{Type} & \textbf{Veg. Score $\uparrow$} \\
        \midrule
        ConvLSTM & $\sim$2M & RNN-based & 0.21 \\
        SGED-ConvLSTM & $\sim$3M & RNN-based & 0.24 \\
        PredRNN & $\sim$24M & Video Pred. & 0.19 \\
        SimVP & $\sim$22M & Video Pred. & 0.22 \\
        Earthformer & $\sim$12M & Transformer & 0.28 \\
        \textbf{Contextformer} & \textbf{6M} & \textbf{Transformer} & \textbf{0.31} \\
        \midrule
        \textbf{Ours (Growth Curve Reg.)} & \textbf{$<$1M} & \textbf{RNN-based} & \textbf{TBD} \\
        \bottomrule
    \end{tabular}
\end{table}

\textit{Note: Vegetation Score evaluation on the full benchmark requires training on the complete GreenEarthNet dataset (23,816 samples). Current results are from preliminary experiments on a subset. Full benchmark evaluation is planned for future work.}

Key differentiators of our approach:
\begin{itemize}
    \item Approximately 6$\times$ fewer parameters than Contextformer
    \item Explicit modeling of vegetation phenology through growth curve parameters
    \item Single forward pass for arbitrary forecast horizons (no autoregressive error accumulation)
    \item Inherent interpretability through predicted growth parameters
\end{itemize}

\section{Interpretability Analysis}
\label{sec:interpretability}

A key motivation for the growth curve formulation is the interpretability of predictions through biophysically meaningful parameters. This section presents preliminary analysis and outlines planned investigations.

\subsection{Feature Importance Analysis}

We utilized Permutation Feature Importance to identify which predictors most strongly influence the model's kNDVI forecasts.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../../images/results/vegetation_dynamics/feature_importance.png}
    \caption{Permutation Feature Importance for kNDVI prediction. Top predictors include temporal features (Cosine of DOY, Step Index) and Radiation.}
    \label{fig:feat_imp}
\end{figure}

Results (Figure~\ref{fig:feat_imp}) indicate that the model relies heavily on temporal context (\texttt{Cos\_DOY}, \texttt{Step\_Index}) to drive the phenological cycle, modulated by meteorological drivers like \texttt{Radiation} and \texttt{Temperature}.

\subsection{Decision Rules Extraction}

To translate the neural network's logic into human-readable form, we trained a surrogate Decision Tree on the model's inputs and outputs. Extracted rules highlighted interactions such as:
\begin{itemize}
    \item \textbf{Seasonality}: \texttt{Cos\_DOY} splits effectively separated growing vs. dormant seasons.
    \item \texttt{Radiation} often served as a secondary splitter, indicating its role in modulating growth rates within a season.
\end{itemize}

\subsection{Extreme Event Analysis (Heatwaves)}

We analyzed the model's behavior during extreme heat events (defined as the top 5\% of maximum temperature anomalies).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{../../images/results/vegetation_dynamics/extreme_event_heatwave.png}
    \caption{Distribution of predicted kNDVI changes (Delta) during Heatwave vs. Normal conditions.}
    \label{fig:heatwave}
\end{figure}

Figure~\ref{fig:heatwave} demonstrates that the model predicts distinct vegetation responses under heatwave conditions, typically associating extreme heat with suppressed growth or browning (negative deltas), aligning with expected physiological stress responses.

\section{Summary}

The experimental results demonstrate that the proposed growth curve regression approach:

\begin{enumerate}
    \item Achieves reasonable prediction accuracy on reflectance delta forecasting (overall MAE = 0.039, RMSE = 0.064)
    \item Exhibits expected temporal error growth over the forecast horizon, but with constrained accumulation due to the trajectory-based formulation
    \item Produces spatially coherent predictions that capture major vegetation dynamics
    \item Maintains dramatically lower parameter count ($<$1M) compared to state-of-the-art transformer models (6--24M)
    \item Provides inherent interpretability through growth curve parameters with biophysical meaning
\end{enumerate}

Full benchmark evaluation on the complete GreenEarthNet dataset and detailed interpretability analyses remain as future work to comprehensively assess the approach's merits relative to existing methods.
